{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyUjMMuV4EsPg2J83n/020"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Data:"
      ],
      "metadata": {
        "id": "XuKMpLfNekfx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfzvP3rOedwo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# read a csv file\n",
        "df = pd.read_csv('file.csv')\n",
        "\n",
        "# read an excel file\n",
        "df = pd.read_excel('file.xlsx')\n",
        "\n",
        "# read data from a sql table\n",
        "from sqlalchemy import create_engine\n",
        "engine = create_engine('postgresql://username:password@host:port/database')\n",
        "df = pd.read_sql_table('table_name', engine)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Exploration:\n"
      ],
      "metadata": {
        "id": "7YSrpzTneqAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# view first 5 rows\n",
        "df.head()\n",
        "\n",
        "# view last 5 rows\n",
        "df.tail()\n",
        "\n",
        "# view the shape of the dataframe\n",
        "df.shape\n",
        "\n",
        "# view the column names\n",
        "df.columns\n",
        "\n",
        "# view the data types of each column\n",
        "df.dtypes\n",
        "\n",
        "# view summary statistics of the dataframe\n",
        "df.describe()\n"
      ],
      "metadata": {
        "id": "9L66rqmaet_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Manipulation:\n"
      ],
      "metadata": {
        "id": "u5IJvYvZexDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select a specific column\n",
        "df['column_name']\n",
        "\n",
        "# select multiple columns\n",
        "df[['column_name1', 'column_name2']]\n",
        "\n",
        "# filter rows based on a condition\n",
        "df[df['column_name'] > value]\n",
        "\n",
        "# drop a column\n",
        "df = df.drop('column_name', axis=1)\n",
        "\n",
        "# rename a column\n",
        "df = df.rename(columns={'old_name': 'new_name'})\n",
        "\n",
        "# sort data by a column\n",
        "df.sort_values(by='column_name')\n",
        "\n",
        "# group data by a column and get the mean of other columns\n",
        "df.groupby('column_name').mean()\n",
        "\n"
      ],
      "metadata": {
        "id": "drbqfs0PezQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Missing Data:\n"
      ],
      "metadata": {
        "id": "5VY1kKhEe6zW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check for missing values\n",
        "df.isnull().sum()\n",
        "\n",
        "# drop rows with missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# fill missing values with a specific value\n",
        "df = df.fillna(value)\n",
        "\n",
        "# fill missing values with the mean of the column\n",
        "df['column_name'].fillna(df['column_name'].mean(), inplace=True)\n"
      ],
      "metadata": {
        "id": "1Kr7O6VGe1nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merging and Joining DataFrames:\n"
      ],
      "metadata": {
        "id": "tr2R6LinfIVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# merge two dataframes on a specific column\n",
        "merged_df = pd.merge(df1, df2, on='column_name')\n",
        "\n",
        "# join two dataframes on the index\n",
        "joined_df = df1.join(df2, on='index')\n"
      ],
      "metadata": {
        "id": "vEirGVCefKsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Transformation:\n"
      ],
      "metadata": {
        "id": "IfnJMCOlfMfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new column based on existing columns\n",
        "df['new_column'] = df['column_name1'] + df['column_name2']\n",
        "\n",
        "# apply a function to a column\n",
        "df['column_name'] = df['column_name'].apply(function)\n",
        "\n",
        "# create dummy variables for categorical columns\n",
        "df = pd.get_dummies(df, columns=['column_name'])\n",
        "\n",
        "# drop duplicate rows\n",
        "df = df.drop_duplicates()\n"
      ],
      "metadata": {
        "id": "tatYPS16fOrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Export:\n"
      ],
      "metadata": {
        "id": "aS5KrnmvfRFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# export dataframe to csv\n",
        "df.to_csv('file.csv', index=False)\n",
        "\n",
        "# export dataframe to excel\n",
        "df.to_excel('file.xlsx', index=False)\n",
        "\n",
        "# export dataframe to sql table\n",
        "from sqlalchemy import create_engine\n",
        "engine = create_engine('postgresql://username:password@host:port/database')\n",
        "df.to_sql('table_name', engine)\n"
      ],
      "metadata": {
        "id": "qZiGYuzEfVVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Filtering & Sorting:\n"
      ],
      "metadata": {
        "id": "fVyMzrU5fXa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter rows based on a condition\n",
        "df[df['column_name'] > value]\n",
        "\n",
        "# filter rows based on multiple conditions\n",
        "df[(df['column_name1'] > value1) & (df['column_name2'] < value2)]\n",
        "\n",
        "# filter rows based on string conditions\n",
        "df[df['column_name'].str.contains(\"string\")]\n",
        "\n",
        "# sort data by a column\n",
        "df.sort_values(by='column_name')\n",
        "\n",
        "# sort data by multiple columns\n",
        "df.sort_values(by=['column_name1','column_name2'])\n",
        "\n",
        "# sort data in descending order\n",
        "df.sort_values(by='column_name',ascending=False)\n"
      ],
      "metadata": {
        "id": "XnjmmA0QfZwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Reshaping and Aggregation:\n"
      ],
      "metadata": {
        "id": "gUp-GfjufnS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pivot data to create a new table\n",
        "df_pivot = df.pivot_table(values='column_name',index='index_column',columns='column_to_be_columns')\n",
        "\n",
        "# stack data to change columns to rows\n",
        "df_stacked = df.stack()\n",
        "\n",
        "# unstack data to change rows to columns\n",
        "df_unstacked = df.unstack()\n",
        "\n",
        "# get the sum of a column\n",
        "df['column_name'].sum()\n",
        "\n",
        "# get the mean of a column\n",
        "df['column_name'].mean()\n",
        "\n",
        "# get the median of a column\n",
        "df['column_name'].median()\n",
        "\n",
        "# get the standard deviation of a column\n",
        "df['column_name'].std()\n",
        "\n",
        "# get the max value of a column\n",
        "df['column_name'].max()\n",
        "\n",
        "# get the min value of a column\n",
        "df['column_name'].min()\n"
      ],
      "metadata": {
        "id": "KhoP3ccFfoD-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}